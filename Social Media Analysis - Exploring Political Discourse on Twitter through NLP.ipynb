{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77dabbe8",
   "metadata": {},
   "source": [
    "### Social Media Analysis: Exploring Political Discourse on Twitter through NLP\n",
    "#### Meier Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01ac50",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This project delves into social media analysis focusing on political discourse, particularly on Twitter. Utilizing Natural Language Processing (NLP) techniques, we aim to conduct topic modeling and sentiment analysis on tweets related to political content.\n",
    "\n",
    "The dataset used in this project is from [Kaggle: Joe Biden Tweets (2007 - 2020)](https://www.kaggle.com/datasets/rohanrao/joe-biden-tweets?select=JoeBidenTweets.csv). It contains 6062 Joe Biden's tweets posted from 24th October 2007 to 31st October 2020.\n",
    "\n",
    "There are six parts in this project, which are introduction, preparation, data preprocessing, descriptive statistics, topic modeling and sentiment analysis.\n",
    "\n",
    "__Preparaction__\n",
    "\n",
    "In this section, the packages and data are imported. And I would sample 100 tweets posted during the campaign for this project.\n",
    "\n",
    "__Data Preprocessing__\n",
    "\n",
    "The data preprocess includes (1) removing URLs and HTML tags, (2) removing punctuations, (3) removing stopwords, (4) lowering case, (5) lemmatization and (5) tokenization.\n",
    "\n",
    "__Descriptive Statistics__\n",
    "\n",
    "To explore the fundamental characteristics of the data, a descriptive analysis will be done in this section.\n",
    "\n",
    "__Topic Modeling__\n",
    "\n",
    "The aim of this project is to analyze the patterns of Biden's tweets for the 2020 presidential campaign. Therefore, I would apply LDA algorithm as it has shown excellent results in practice and visualize the result by pyLDAvis package.\n",
    "\n",
    "__Sentiment Analysis__\n",
    "\n",
    "To explore further, sentiment analysis will be done by using Hugging face transformers. I will display the top 10 common words by different sentiments.\n",
    "\n",
    "\n",
    "__Reference__\n",
    "\n",
    "* Kedia, A. (2020). Hands-on python natural language processing: Explore tools and techniques to analyze and process text with a view to building real-world nlp applications. Packt Publishing Limited.\n",
    "* PÃ©rez, J. M., Giudici, J. C., & Luque, F. (2021). pysentimiento: A python toolkit for sentiment analysis and socialnlp tasks. arXiv preprint arXiv:2106.09462."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efecbd",
   "metadata": {},
   "source": [
    "### Preparaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020bb2df",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mayye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mayye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:18: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:43: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:29: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO_DIM = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:73: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:80: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:66: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORSHAPEPROTO = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:19: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:33: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:37: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:41: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:45: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:49: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:53: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:57: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:61: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:65: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:69: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:73: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:77: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:81: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:85: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:89: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:93: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:97: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:101: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:105: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:109: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:113: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:117: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:121: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:125: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:129: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:133: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:137: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:141: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:145: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:149: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:153: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:157: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:161: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:165: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:169: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:173: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:177: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:181: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:185: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:189: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:193: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:197: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:201: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:205: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:209: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:213: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:217: DeprecationWarning: Call to deprecated create function EnumValueDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.EnumValueDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:27: DeprecationWarning: Call to deprecated create function EnumDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _DATATYPE = _descriptor.EnumDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:287: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\types_pb2.py:280: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _SERIALIZEDDTYPE = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:20: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:39: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:46: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:32: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO_DTYPEANDSHAPE = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:76: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:83: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:90: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:97: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:104: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:111: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:69: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _RESOURCEHANDLEPROTO = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:47: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:54: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:61: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:68: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:75: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:82: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:89: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:96: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:103: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:110: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:117: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:124: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:131: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:138: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:145: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:152: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:33: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _TENSORPROTO = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:183: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:190: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:197: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:176: DeprecationWarning: Call to deprecated create function Descriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _VARIANTTENSORDATAPROTO = _descriptor.Descriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:21: DeprecationWarning: Call to deprecated create function FileDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  DESCRIPTOR = _descriptor.FileDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:40: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:47: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:54: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:61: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:68: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:75: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n",
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:82: DeprecationWarning: Call to deprecated create function FieldDescriptor(). Note: Create unlinked descriptors is going to go away. Please use get/find descriptors from generated code or query the descriptor_pool.\n",
      "  _descriptor.FieldDescriptor(\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from transformers import pipeline\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd2aae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>quotes</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361388562</td>\n",
       "      <td>2007-10-24 22:45</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/361388562</td>\n",
       "      <td>Tune in 11:30 ET tomorrow for a live webcast o...</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>543984392</td>\n",
       "      <td>2007-12-29 15:35</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/543984392</td>\n",
       "      <td>Iowans, there's a good chance there's a Biden ...</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189287227321356289</td>\n",
       "      <td>2012-04-09 09:42</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1892872273...</td>\n",
       "      <td>We're excited to announce that @JoeBiden is be...</td>\n",
       "      <td>21</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189287350034104320</td>\n",
       "      <td>2012-04-09 09:43</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1892873500...</td>\n",
       "      <td>Campaign staff will run this account to keep y...</td>\n",
       "      <td>144</td>\n",
       "      <td>76</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189339650610036736</td>\n",
       "      <td>2012-04-09 13:11</td>\n",
       "      <td>https://twitter.com/JoeBiden/status/1893396506...</td>\n",
       "      <td>News for you this morning: VP Biden will speak...</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id         timestamp  \\\n",
       "0           361388562  2007-10-24 22:45   \n",
       "1           543984392  2007-12-29 15:35   \n",
       "2  189287227321356289  2012-04-09 09:42   \n",
       "3  189287350034104320  2012-04-09 09:43   \n",
       "4  189339650610036736  2012-04-09 13:11   \n",
       "\n",
       "                                                 url  \\\n",
       "0      https://twitter.com/JoeBiden/status/361388562   \n",
       "1      https://twitter.com/JoeBiden/status/543984392   \n",
       "2  https://twitter.com/JoeBiden/status/1892872273...   \n",
       "3  https://twitter.com/JoeBiden/status/1892873500...   \n",
       "4  https://twitter.com/JoeBiden/status/1893396506...   \n",
       "\n",
       "                                               tweet  replies  retweets  \\\n",
       "0  Tune in 11:30 ET tomorrow for a live webcast o...       19         5   \n",
       "1  Iowans, there's a good chance there's a Biden ...       13        16   \n",
       "2  We're excited to announce that @JoeBiden is be...       21        82   \n",
       "3  Campaign staff will run this account to keep y...      144        76   \n",
       "4  News for you this morning: VP Biden will speak...       10        54   \n",
       "\n",
       "   quotes  likes  \n",
       "0      17     11  \n",
       "1       6     22  \n",
       "2       1     20  \n",
       "3      37     51  \n",
       "4       0      5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"JoeBidenTweets.csv\")\n",
    "\n",
    "# remove missing and duplicate values\n",
    "df.dropna(axis = \"columns\", inplace = True)\n",
    "df.drop_duplicates(inplace = True, subset = \"tweet\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb30e19",
   "metadata": {},
   "source": [
    "My aim is to explore the patterns of Biden's tweets for the 2020 presidential campaign. Therefore, I would extract the tweets posted after 25th of April, 2019, which is the date that Biden officially posted a video and claimed to join the campaign. Firstly, I convert the timestamp column to DateTime format. Then, I check the time of the last tweet in this dataset and the amount of tweets posted during the campaign to ensure I can get enough data for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db61bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 13:01:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4722"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert column timestamp to DateTime format\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# the last tweet\n",
    "df.sort_values('timestamp', ascending = True, inplace = True)\n",
    "last_tweet = df.timestamp.iloc[-1]\n",
    "print(last_tweet)\n",
    "\n",
    "# the amount of tweet posted during the campaign\n",
    "df_cam = df.loc[df['timestamp'] >= '2019-04-25']\n",
    "len(df_cam.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c488c68c",
   "metadata": {},
   "source": [
    "The last tweet was posted on 2020.11.01, and 4722 tweets were posted during the campaign. For this project, I would sample 100 tweets randomly for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398f4caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two years ago, President Trump attempted to en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If President Trump is successful in forcing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say this hate began with Donald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wear a mask. https://t.co/HBDMNA4ary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The events of this past week in Syria have mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The New Hampshire primary is just one day away...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My running mate will be a woman. #DemDebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Donald Trump doesnât think it matters if candi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>We must seek not to build walls, but bridges.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The powerful gun lobby has controlled our poli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet\n",
       "0   Two years ago, President Trump attempted to en...\n",
       "1   If President Trump is successful in forcing th...\n",
       "2   I wish I could say this hate began with Donald...\n",
       "3                Wear a mask. https://t.co/HBDMNA4ary\n",
       "4   The events of this past week in Syria have mad...\n",
       "..                                                ...\n",
       "95  The New Hampshire primary is just one day away...\n",
       "96        My running mate will be a woman. #DemDebate\n",
       "97  Donald Trump doesnât think it matters if candi...\n",
       "98  We must seek not to build walls, but bridges.\\...\n",
       "99  The powerful gun lobby has controlled our poli...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 100 tweets\n",
    "sample_df = df_cam.sample(n = 100, ignore_index=True, random_state = 100)\n",
    "tweets = sample_df[['tweet']]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b12d89",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f9591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two years ago, President Trump attempted to end DACAâthrowing lives into chaos &amp;amp; forcing our DREAMers to live in fear as the Supreme Court decides their fate. It's cruel.\\n \\nDREAMers are Americans. It's time for Congress to keep our promise to them &amp;amp; provide a path to citizenship.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If President Trump is successful in forcing through his nominee to the U.S. Supreme Court, it will likely repeal the ACA and 100 million Americans with pre-existing conditions will lose their protections.\\n \\nVote like your health care depends on it. Because it does. https://t.co/XgY2aGRZq2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>We must seek not to build walls, but bridges.\\n\\nWe must seek not to clench our fists, but to open our arms.\\n\\nWe must seek not to tear each other apart, but to come together.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The powerful gun lobby has controlled our politics for far too long. Enough is enough. We the people own this country â not the @NRA.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                  tweet\n",
       "0    Two years ago, President Trump attempted to end DACAâthrowing lives into chaos &amp; forcing our DREAMers to live in fear as the Supreme Court decides their fate. It's cruel.\\n \\nDREAMers are Americans. It's time for Congress to keep our promise to them &amp; provide a path to citizenship.\n",
       "1   If President Trump is successful in forcing through his nominee to the U.S. Supreme Court, it will likely repeal the ACA and 100 million Americans with pre-existing conditions will lose their protections.\\n \\nVote like your health care depends on it. Because it does. https://t.co/XgY2aGRZq2\n",
       "..                                                                                                                                                                                                                                                                                                  ...\n",
       "98                                                                                                                     We must seek not to build walls, but bridges.\\n\\nWe must seek not to clench our fists, but to open our arms.\\n\\nWe must seek not to tear each other apart, but to come together.\n",
       "99                                                                                                                                                                The powerful gun lobby has controlled our politics for far too long. Enough is enough. We the people own this country â not the @NRA.\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look of the data\n",
    "with pd.option_context('display.max_rows',5, 'display.max_colwidth', None): \n",
    "    display(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb16e2d",
   "metadata": {},
   "source": [
    "As it is shown above, the tweets contain URL links and HTML parsers. Therefore, I clean them first and save the result for sentiment analysis. After that, I preprocess the data by removing punctuations, lowering case, removing stopwords and lemmatization. I keep the @ and # as I also want to look at the users and hashtags in the tweets. Finally, I tokenize the tweets into bigrams for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dfe135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\265773698.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['cleaned_tweets'] = tweets['tweet'].apply(remove_links)\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\265773698.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['cleaned_tweets_sa'] = tweets['cleaned_tweets']\n"
     ]
    }
   ],
   "source": [
    "# remove URLs and ampersand by HTML parsers (&amp)\n",
    "def remove_links(tweet):\n",
    "        tweet = re.sub(r'http[^\\s]+','',str(tweet))\n",
    "        tweet = re.sub('&amp','',str(tweet))\n",
    "        return tweet\n",
    "    \n",
    "tweets['cleaned_tweets'] = tweets['tweet'].apply(remove_links)\n",
    "tweets['cleaned_tweets_sa'] = tweets['cleaned_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b100b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.Series(tweets.cleaned_tweets.tolist()).astype(str)\n",
    "\n",
    "# remove punctuations (expect for @ and #) and lowering case \n",
    "def text_clean(corpus, keep_list):\n",
    "    cleaned_corpus = pd.Series()\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9@#]',repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6262b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "def stopwords_removal(corpus):\n",
    "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for word in wh_words:\n",
    "        stop.remove(word)\n",
    "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70655bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "def lemmatize(corpus):\n",
    "    lem = WordNetLemmatizer()\n",
    "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "186f1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, keep_list, cleaning = True, lemmatization = True, remove_stopwords = True):\n",
    " \n",
    "    if cleaning == True:\n",
    "        corpus = text_clean(corpus, keep_list)\n",
    "    \n",
    "    if remove_stopwords == True:\n",
    "        corpus = stopwords_removal(corpus)\n",
    "    else :\n",
    "        corpus = [[x for x in x.split()] for x in corpus]\n",
    "    \n",
    "    if lemmatization == True:\n",
    "        corpus = lemmatize(corpus)\n",
    "        \n",
    "        \n",
    "    corpus = [' '.join(x) for x in corpus]        \n",
    "\n",
    "    return corpus\n",
    "\n",
    "keep_list = ['U.S.A', 'U.S.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19e5882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:5: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  cleaned_corpus = pd.Series()\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3630001099.py:14: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3121341577.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['cleaned_tweets'] = pd.Series(cleaned_corpus)\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = preprocess(corpus, keep_list, cleaning = True, lemmatization = True, remove_stopwords = True)\n",
    "tweets['cleaned_tweets'] = pd.Series(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e2a2281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\1652660611.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['bigrams'] = tweets['cleaned_tweets'].apply(generate_bigrams)\n"
     ]
    }
   ],
   "source": [
    "# tokenization: bigrams\n",
    "def generate_bigrams(text,ngram=2):\n",
    "    \n",
    "    words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]  \n",
    "    temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "    ans=[' '.join(ngram) for ngram in temp]\n",
    "\n",
    "    return ans\n",
    "\n",
    "tweets['bigrams'] = tweets['cleaned_tweets'].apply(generate_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0570a431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>cleaned_tweets_sa</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two years ago, President Trump attempted to en...</td>\n",
       "      <td>two years ago president trump attempt end daca...</td>\n",
       "      <td>Two years ago, President Trump attempted to en...</td>\n",
       "      <td>[two years, years ago, ago president, presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If President Trump is successful in forcing th...</td>\n",
       "      <td>president trump successful force nominee U.S. ...</td>\n",
       "      <td>If President Trump is successful in forcing th...</td>\n",
       "      <td>[president trump, trump successful, successful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wish I could say this hate began with Donald...</td>\n",
       "      <td>wish could say hate begin donald trump end ame...</td>\n",
       "      <td>I wish I could say this hate began with Donald...</td>\n",
       "      <td>[wish could, could say, say hate, hate begin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wear a mask. https://t.co/HBDMNA4ary</td>\n",
       "      <td>wear mask</td>\n",
       "      <td>Wear a mask.</td>\n",
       "      <td>[wear mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The events of this past week in Syria have mad...</td>\n",
       "      <td>events past week syria make clear how dangerou...</td>\n",
       "      <td>The events of this past week in Syria have mad...</td>\n",
       "      <td>[events past, past week, week syria, syria mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The New Hampshire primary is just one day away...</td>\n",
       "      <td>new hampshire primary one day away need help t...</td>\n",
       "      <td>The New Hampshire primary is just one day away...</td>\n",
       "      <td>[new hampshire, hampshire primary, primary one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My running mate will be a woman. #DemDebate</td>\n",
       "      <td>run mate woman #demdebate</td>\n",
       "      <td>My running mate will be a woman. #DemDebate</td>\n",
       "      <td>[run mate, mate woman, woman #demdebate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Donald Trump doesnât think it matters if candi...</td>\n",
       "      <td>donald trump think matter candidates accept da...</td>\n",
       "      <td>Donald Trump doesnât think it matters if candi...</td>\n",
       "      <td>[donald trump, trump think, think matter, matt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>We must seek not to build walls, but bridges.\\...</td>\n",
       "      <td>must seek build wall bridge must seek clench f...</td>\n",
       "      <td>We must seek not to build walls, but bridges.\\...</td>\n",
       "      <td>[must seek, seek build, build wall, wall bridg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The powerful gun lobby has controlled our poli...</td>\n",
       "      <td>powerful gun lobby control politics far long e...</td>\n",
       "      <td>The powerful gun lobby has controlled our poli...</td>\n",
       "      <td>[powerful gun, gun lobby, lobby control, contr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "0   Two years ago, President Trump attempted to en...   \n",
       "1   If President Trump is successful in forcing th...   \n",
       "2   I wish I could say this hate began with Donald...   \n",
       "3                Wear a mask. https://t.co/HBDMNA4ary   \n",
       "4   The events of this past week in Syria have mad...   \n",
       "..                                                ...   \n",
       "95  The New Hampshire primary is just one day away...   \n",
       "96        My running mate will be a woman. #DemDebate   \n",
       "97  Donald Trump doesnât think it matters if candi...   \n",
       "98  We must seek not to build walls, but bridges.\\...   \n",
       "99  The powerful gun lobby has controlled our poli...   \n",
       "\n",
       "                                       cleaned_tweets  \\\n",
       "0   two years ago president trump attempt end daca...   \n",
       "1   president trump successful force nominee U.S. ...   \n",
       "2   wish could say hate begin donald trump end ame...   \n",
       "3                                           wear mask   \n",
       "4   events past week syria make clear how dangerou...   \n",
       "..                                                ...   \n",
       "95  new hampshire primary one day away need help t...   \n",
       "96                          run mate woman #demdebate   \n",
       "97  donald trump think matter candidates accept da...   \n",
       "98  must seek build wall bridge must seek clench f...   \n",
       "99  powerful gun lobby control politics far long e...   \n",
       "\n",
       "                                    cleaned_tweets_sa  \\\n",
       "0   Two years ago, President Trump attempted to en...   \n",
       "1   If President Trump is successful in forcing th...   \n",
       "2   I wish I could say this hate began with Donald...   \n",
       "3                                       Wear a mask.    \n",
       "4   The events of this past week in Syria have mad...   \n",
       "..                                                ...   \n",
       "95  The New Hampshire primary is just one day away...   \n",
       "96        My running mate will be a woman. #DemDebate   \n",
       "97  Donald Trump doesnât think it matters if candi...   \n",
       "98  We must seek not to build walls, but bridges.\\...   \n",
       "99  The powerful gun lobby has controlled our poli...   \n",
       "\n",
       "                                              bigrams  \n",
       "0   [two years, years ago, ago president, presiden...  \n",
       "1   [president trump, trump successful, successful...  \n",
       "2   [wish could, could say, say hate, hate begin, ...  \n",
       "3                                         [wear mask]  \n",
       "4   [events past, past week, week syria, syria mak...  \n",
       "..                                                ...  \n",
       "95  [new hampshire, hampshire primary, primary one...  \n",
       "96           [run mate, mate woman, woman #demdebate]  \n",
       "97  [donald trump, trump think, think matter, matt...  \n",
       "98  [must seek, seek build, build wall, wall bridg...  \n",
       "99  [powerful gun, gun lobby, lobby control, contr...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068aa70b",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942f2789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3656988466.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['original_tweet_word_count'] = tweets['tweet'].apply(word_count)\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3656988466.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['cleaned_tweet_word_count'] = tweets['cleaned_tweets'].apply(word_count)\n",
      "C:\\Users\\mayye\\AppData\\Local\\Temp\\ipykernel_17060\\3656988466.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['bigram_count'] = tweets['bigrams'].str.len()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>Two years ago, President Trump attempted to en...</td>\n",
       "      <td>If President Trump is successful in forcing th...</td>\n",
       "      <td>I wish I could say this hate began with Donald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <td>two years ago president trump attempt end daca...</td>\n",
       "      <td>president trump successful force nominee U.S. ...</td>\n",
       "      <td>wish could say hate begin donald trump end ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaned_tweets_sa</th>\n",
       "      <td>Two years ago, President Trump attempted to en...</td>\n",
       "      <td>If President Trump is successful in forcing th...</td>\n",
       "      <td>I wish I could say this hate began with Donald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigrams</th>\n",
       "      <td>[two years, years ago, ago president, presiden...</td>\n",
       "      <td>[president trump, trump successful, successful...</td>\n",
       "      <td>[wish could, could say, say hate, hate begin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_tweet_word_count</th>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaned_tweet_word_count</th>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigram_count</th>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           0  \\\n",
       "tweet                      Two years ago, President Trump attempted to en...   \n",
       "cleaned_tweets             two years ago president trump attempt end daca...   \n",
       "cleaned_tweets_sa          Two years ago, President Trump attempted to en...   \n",
       "bigrams                    [two years, years ago, ago president, presiden...   \n",
       "original_tweet_word_count                                                 48   \n",
       "cleaned_tweet_word_count                                                  29   \n",
       "bigram_count                                                              28   \n",
       "\n",
       "                                                                           1  \\\n",
       "tweet                      If President Trump is successful in forcing th...   \n",
       "cleaned_tweets             president trump successful force nominee U.S. ...   \n",
       "cleaned_tweets_sa          If President Trump is successful in forcing th...   \n",
       "bigrams                    [president trump, trump successful, successful...   \n",
       "original_tweet_word_count                                                 44   \n",
       "cleaned_tweet_word_count                                                  24   \n",
       "bigram_count                                                              23   \n",
       "\n",
       "                                                                           2  \n",
       "tweet                      I wish I could say this hate began with Donald...  \n",
       "cleaned_tweets             wish could say hate begin donald trump end ame...  \n",
       "cleaned_tweets_sa          I wish I could say this hate began with Donald...  \n",
       "bigrams                    [wish could, could say, say hate, hate begin, ...  \n",
       "original_tweet_word_count                                                 51  \n",
       "cleaned_tweet_word_count                                                  22  \n",
       "bigram_count                                                              21  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word count\n",
    "def word_count(text):\n",
    "   \n",
    "    return len(text.split())\n",
    "\n",
    "tweets['original_tweet_word_count'] = tweets['tweet'].apply(word_count)\n",
    "tweets['cleaned_tweet_word_count'] = tweets['cleaned_tweets'].apply(word_count)\n",
    "tweets['bigram_count'] = tweets['bigrams'].str.len()\n",
    "\n",
    "tweets.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb28a0",
   "metadata": {},
   "source": [
    "The table above shows the word count for original tweets, tweets after preprocessing and bigrams. To save space, only the first three tweets are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce3fe9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# top 10 bigrams - all sample data\n",
    "def get_top_ngram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx])\n",
    "                  for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:10]\n",
    "\n",
    "top_10_bigrams = get_top_ngram(tweets['cleaned_tweets'],2)[:10] \n",
    "x,y = map(list,zip(*top_10_bigrams)) \n",
    "sns.barplot(x = y,y = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1f3fc",
   "metadata": {},
   "source": [
    "The bar chart shows the top 10 bigrams in the sample data. From this chart, we can tell Biden mentioned president Donald Trump a lot which quite makes sense as they are competitors. Following, I will explore further on Biden's tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f6fda",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f072240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.7251205523133859\n"
     ]
    }
   ],
   "source": [
    "# LDA model by bigrams\n",
    "id2word = Dictionary(tweets['bigrams'])\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus_bigrams = [id2word.doc2bow(text) for text in tweets['bigrams']]\n",
    "\n",
    "[[(id2word[i], freq) for i, freq in doc] for doc in corpus_bigrams[:1]]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model_bigrams = LdaModel(corpus=corpus_bigrams,\n",
    "                   id2word=id2word,\n",
    "                   num_topics=2, \n",
    "                   random_state=100,\n",
    "                   update_every=1,\n",
    "                   chunksize=100,\n",
    "                   alpha='auto',\n",
    "                   per_word_topics=True)\n",
    "\n",
    "coherence_model_lda_bigrams = CoherenceModel(model=lda_model_bigrams, texts=tweets['bigrams'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda_bigrams.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2df7733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayye\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1706021217782063042652836452\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1706021217782063042652836452_data = {\"mdsDat\": {\"x\": [0.0226399557216157, -0.0226399557216157], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [50.266905925137415, 49.733094074862585]}, \"tinfo\": {\"Term\": [\"save people\", \"best wish\", \"must seek\", \"send best\", \"hard work\", \"government work\", \"work everyone\", \"fail protect\", \"day one\", \"filipino american\", \"safe harbor\", \"million americans\", \"president intentionally\", \"governments interfere\", \"american people\", \"interfere elections\", \"need test\", \"must impeach\", \"leadership climate\", \"people live\", \"one rejoin\", \"years planet\", \"dangerous give\", \"rejoin paris\", \"recover day\", \"pretty simple\", \"live need\", \"give four\", \"world push\", \"agreement rally\", \"save people\", \"fail protect\", \"day one\", \"president intentionally\", \"governments interfere\", \"interfere elections\", \"need test\", \"must impeach\", \"leadership climate\", \"people live\", \"one rejoin\", \"years planet\", \"dangerous give\", \"rejoin paris\", \"recover day\", \"pretty simple\", \"live need\", \"give four\", \"world push\", \"agreement rally\", \"simple want\", \"test need\", \"job save\", \"planet may\", \"trump administration\", \"violate oath\", \"ask three\", \"intentionally slow\", \"abdication american\", \"paris agreement\", \"filipino american\", \"american people\", \"people job\", \"president trump\", \"donald trump\", \"climate change\", \"every american\", \"million people\", \"gun violence\", \"american history\", \"americans time\", \"lead way\", \"middle class\", \"backbone america\", \"trump continue\", \"national security\", \"fast need\", \"make clear\", \"years ago\", \"provide path\", \"job president\", \"thank support\", \"make history\", \"exist condition\", \"every day\", \"repeal aca\", \"pre exist\", \"covid 19\", \"four years\", \"best wish\", \"send best\", \"hard work\", \"government work\", \"work everyone\", \"must seek\", \"paryushan das\", \"dukkaddam kshamavani\", \"conclude holy\", \"@drbiden send\", \"beat donald\", \"peace reconciliation\", \"may find\", \"wish members\", \"bible st\", \"find peace\", \"michhami dukkaddam\", \"members jain\", \"could learn\", \"church yesterday\", \"faith conclude\", \"19 20\", \"reconciliation live\", \"supporters tuesday\", \"negligence incompetence\", \"something call\", \"lakshan may\", \"brandish could\", \"one another\", \"das lakshan\", \"safe harbor\", \"million americans\", \"donald trump\", \"stake election\", \"covid 19\", \"president trump\", \"every day\", \"around world\", \"job president\", \"new hampshire\", \"white house\", \"four years\", \"step lead\", \"far long\", \"nation us\", \"battle soul\", \"american history\", \"back better\", \"election day\", \"years ago\", \"soul nation\", \"men women\", \"main street\", \"middle class\"], \"Freq\": [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.287654860422394, 1.2030623271158432, 1.1912882774407596, 0.7814963199941354, 0.7813940076284203, 0.7797593046337783, 0.7790867203529926, 0.7784169568336917, 0.7783549478905456, 0.7781524267778496, 0.7776995272262515, 0.7775822504818125, 0.7774003830803263, 0.7772895128111237, 0.7771194065507431, 0.7769214751516491, 0.7769307501978869, 0.7766508254776708, 0.7765763860601855, 0.7765116997841048, 0.7758460000737225, 0.775783130559276, 0.7751785792207393, 0.774778796042183, 0.7747609152829412, 0.7746626189166279, 0.7745746972154363, 0.7744909349421965, 0.7743010833514231, 0.773926830454779, 1.1390208101772388, 1.4141834156739659, 1.0830830063174772, 3.612979710306495, 5.329103459298754, 1.0714607040483655, 1.066289244247113, 1.0649220833078645, 1.049170855558428, 1.4457134094544521, 1.0096084804979992, 1.0019183197385189, 1.1834277235637984, 0.9862801136865359, 0.9698977046977667, 0.9580637975077879, 0.9420033378044047, 0.9398373754603108, 1.0713968305340686, 0.9289284867992373, 1.1589251550224449, 0.9248074020796496, 0.920453293775718, 0.914037352255042, 1.1104051889151012, 0.9082932300628845, 0.8905088548067172, 1.003995738857704, 0.9208650293334466, 1.2257889043687207, 1.2101062759905155, 1.2015153228559403, 1.1822920600540527, 1.1807904170730472, 1.552845761754261, 0.7493742918949471, 0.7479905723043418, 0.7477894450456247, 0.7475660859403419, 0.747187435021708, 0.7459964229692058, 0.7457440678597852, 0.7455062817051353, 0.745284199748485, 0.7452660831586241, 0.7452381750959141, 0.7451489165970431, 0.7448214462273114, 0.7441967313388171, 0.7440931403941815, 0.743690412858735, 0.7432395793914648, 0.7432470530760549, 0.7431496586673769, 0.7431204734560344, 0.743040391506597, 0.7427793328657549, 0.7422198471611202, 0.7421451103152188, 1.0920062606645573, 1.0868146041716686, 6.032538720810799, 1.0367268214809107, 1.5698133908639598, 3.1201234922629073, 1.467863818730109, 1.225522122209933, 1.4211969969059888, 0.9724229554564603, 0.9617505338617273, 1.1431523738554417, 0.953418321579735, 0.9437148300808541, 0.9133477359334397, 0.905282778828247, 1.1462207470959087, 0.8967852940528499, 0.8925123331429351, 0.9987968315462773, 0.8775874796200097, 0.8717520456127418, 0.8393199440319884, 0.8912450232850916], \"Total\": [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5724823962092156, 1.5690321531668263, 1.5686083598977216, 1.045278243785904, 1.045304663272164, 1.0452401435684715, 1.0451640586517623, 1.0451569697164216, 1.045132754912437, 1.0450999763133597, 1.0451312816497809, 1.0451345771966096, 1.0451106741602425, 1.0450735000973148, 1.0450879891161309, 1.0450290777107738, 1.0450700686147185, 1.0450714004044583, 1.0450392724481494, 1.0450481877747415, 1.045014061714028, 1.0450180059937813, 1.0450009903279929, 1.0449798580680705, 1.0450079073577974, 1.0449885813485933, 1.0449992602520102, 1.044954238153956, 1.0449930907720015, 1.044946781263101, 1.566386009100273, 2.0842530686306056, 1.564180780921202, 6.733103202569403, 11.361642180109552, 1.5636417163902754, 1.5634382228640205, 1.563429427749932, 1.5627671907735972, 2.591934156550361, 1.5611249668731513, 1.5607407112149514, 2.07467274684889, 1.5601546951347336, 1.5594437039972844, 1.5590266068475775, 1.558402995363346, 1.558257151043249, 2.070193662080346, 1.5577406100119828, 2.5801221519284336, 1.557582659404427, 1.5573371855530294, 1.5571618652687302, 2.5782690076452104, 1.5569774548846258, 1.5561402743600372, 2.573809129721664, 2.0640174031888883, 1.5322930146263862, 1.5328601238281374, 1.5332797107802105, 1.5341127075628094, 1.5341923882510622, 2.046393968441506, 1.024487510160934, 1.024544602070037, 1.024558259065047, 1.0245180104086842, 1.0245724180922224, 1.02460038138199, 1.0246100463287853, 1.0246272044218814, 1.0246474689053293, 1.0246490020268277, 1.0246400982470016, 1.0246594629700487, 1.0246569299804964, 1.0246801535669343, 1.0246926680335786, 1.024723046909821, 1.0247024512832381, 1.02473849115405, 1.0247395365402354, 1.0247356425632215, 1.0247346614591466, 1.024738204588422, 1.0247805450798726, 1.0247347090868097, 1.537974914437738, 1.5381808567600423, 11.361642180109552, 1.5402726674411302, 2.573809129721664, 6.733103202569403, 2.5782690076452104, 2.060479569670772, 2.5801221519284336, 1.5430383340948037, 1.5435914435901776, 2.0640174031888883, 1.5439002277355833, 1.5443193973958196, 1.5456470964329196, 1.5459401990353574, 2.591934156550361, 1.5463289256984578, 1.5464864727001442, 2.070193662080346, 1.5471273938114174, 1.5474495865061528, 1.548741983331443, 2.07467274684889], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.4581, -6.5261, -6.5359, -6.9575, -6.9576, -6.9597, -6.9606, -6.9615, -6.9615, -6.9618, -6.9624, -6.9625, -6.9628, -6.9629, -6.9631, -6.9634, -6.9634, -6.9637, -6.9638, -6.9639, -6.9648, -6.9648, -6.9656, -6.9661, -6.9662, -6.9663, -6.9664, -6.9665, -6.9668, -6.9672, -6.5808, -6.3644, -6.6312, -5.4264, -5.0378, -6.6419, -6.6468, -6.6481, -6.663, -6.3424, -6.7014, -6.709, -6.5425, -6.7248, -6.7415, -6.7538, -6.7707, -6.773, -6.642, -6.7847, -6.5635, -6.7891, -6.7939, -6.8008, -6.6062, -6.8072, -6.8269, -6.707, -6.7934, -6.4967, -6.5096, -6.5167, -6.5328, -6.5341, -6.2602, -6.9888, -6.9907, -6.9909, -6.9912, -6.9917, -6.9933, -6.9937, -6.994, -6.9943, -6.9943, -6.9943, -6.9945, -6.9949, -6.9957, -6.9959, -6.9964, -6.997, -6.997, -6.9971, -6.9972, -6.9973, -6.9976, -6.9984, -6.9985, -6.6123, -6.617, -4.9031, -6.6642, -6.2493, -5.5624, -6.3165, -6.4969, -6.3488, -6.7283, -6.7393, -6.5665, -6.748, -6.7582, -6.7909, -6.7998, -6.5638, -6.8092, -6.814, -6.7015, -6.8309, -6.8375, -6.8754, -6.8154], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.488, 0.4222, 0.4127, 0.397, 0.3968, 0.3948, 0.394, 0.3932, 0.3931, 0.3929, 0.3923, 0.3921, 0.3919, 0.3918, 0.3916, 0.3914, 0.3913, 0.391, 0.3909, 0.3908, 0.39, 0.3899, 0.3891, 0.3886, 0.3886, 0.3885, 0.3884, 0.3883, 0.388, 0.3876, 0.3692, 0.3, 0.3203, 0.0653, -0.0692, 0.3098, 0.3051, 0.3038, 0.2894, 0.104, 0.252, 0.2446, 0.1264, 0.2292, 0.2129, 0.2009, 0.1844, 0.1822, 0.0291, 0.1709, -0.1125, 0.1665, 0.162, 0.1551, -0.1546, 0.1489, 0.1297, -0.2536, -0.1193, 0.4753, 0.4621, 0.4547, 0.438, 0.4367, 0.4225, 0.3858, 0.3839, 0.3836, 0.3833, 0.3828, 0.3812, 0.3808, 0.3805, 0.3802, 0.3801, 0.3801, 0.38, 0.3795, 0.3787, 0.3785, 0.3779, 0.3774, 0.3773, 0.3772, 0.3772, 0.3771, 0.3767, 0.3759, 0.3759, 0.356, 0.3512, 0.0654, 0.3026, 0.2041, -0.0707, 0.1352, 0.1789, 0.1022, 0.2368, 0.2254, 0.1076, 0.2165, 0.206, 0.1724, 0.1634, -0.1174, 0.1537, 0.1488, -0.0303, 0.1315, 0.1246, 0.0859, -0.1464]}, \"token.table\": {\"Topic\": [2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1], \"Freq\": [0.9758734352814876, 0.9760687365574922, 0.9569441260719127, 0.9568936740891688, 0.3858122697572353, 0.3858122697572353, 0.47978818649743876, 0.47978818649743876, 0.6405637096451963, 0.6405637096451963, 0.48532390940415016, 0.48532390940415016, 0.9569384764529324, 0.64669294053871, 0.64669294053871, 0.6409620809516205, 0.6409620809516205, 0.6468555514786306, 0.6468555514786306, 0.9760169045561691, 0.6526166930571217, 0.9759454157129172, 0.9758590003986845, 0.9759142855641127, 0.6395326944260203, 0.9760303927592585, 0.97593640441102, 0.388529199174976, 0.777058398349952, 0.9568364621321188, 0.9758623291789813, 0.6375077588297459, 0.44007722833881646, 0.5280926740065798, 0.9760434030685965, 0.6466270592422407, 0.6466270592422407, 0.6396159345318595, 0.387857123145316, 0.387857123145316, 0.6421939955660442, 0.6421939955660442, 0.6373355689248744, 0.9759023668228595, 0.6475344424775707, 0.6475344424775707, 0.6416825448714228, 0.6416825448714228, 0.6384122395056354, 0.9759439554637048, 0.4844920389019051, 0.4844920389019051, 0.9568724200212396, 0.6518425895765277, 0.9566588910735891, 0.6398905773706335, 0.6398905773706335, 0.6521967211652134, 0.9569797063712825, 0.9567179429082959, 0.3875785490437267, 0.3875785490437267, 0.956936892170917, 0.975862374535154, 0.6407214169620491, 0.6407214169620491, 0.9568162468353427, 0.9568736394159095, 0.6456853438226915, 0.6456853438226915, 0.641742602837088, 0.641742602837088, 0.6421216993190129, 0.6421216993190129, 0.9759810608758288, 0.9759339918663597, 0.6462246064234054, 0.6462246064234054, 0.9759524360903336, 0.4820037287899245, 0.4820037287899245, 0.6501186096583966, 0.6396195327084174, 0.956794078760558, 0.9773289165444332, 0.6469782153428316, 0.6469782153428316, 0.6414258715071228, 0.6414258715071228, 0.956787589203916, 0.9758577319815707, 0.6480720393681162, 0.6480720393681162, 0.9758186811812073, 0.9568175956052724, 0.956986535516411, 0.9760977953190592, 0.9759902672017272, 0.6393122919021318, 0.9568462564964818, 0.956956243968924, 0.6426155896590042, 0.6426155896590042, 0.9566830706990415, 0.5940797102996387, 0.44555978272472896, 0.956911172453293, 0.641955402313295, 0.641955402313295, 0.9758930494873871, 0.9568572315578294, 0.9568704975361851, 0.6422700578372225, 0.6422700578372225, 0.6502056637026398, 0.6359371668711209, 0.6523752457612492, 0.9569249224836304, 0.9758614402234034, 0.6463591841241045, 0.6463591841241045, 0.6492356977685708, 0.6492356977685708, 0.6477102483925958, 0.6477102483925958, 0.9758587275020871, 0.9569213106993593, 0.6420205014238988, 0.6420205014238988, 0.9569305580934832, 0.6412543123145287, 0.6412543123145287, 0.9569482555584158, 0.647839818076563, 0.647839818076563, 0.9759647173961415, 0.651808735109143, 0.9569018374375169, 0.48304659526157373, 0.48304659526157373, 0.9568145785419565], \"Term\": [\"19 20\", \"@drbiden send\", \"abdication american\", \"agreement rally\", \"american history\", \"american history\", \"american people\", \"american people\", \"americans time\", \"americans time\", \"around world\", \"around world\", \"ask three\", \"back better\", \"back better\", \"backbone america\", \"backbone america\", \"battle soul\", \"battle soul\", \"beat donald\", \"best wish\", \"bible st\", \"brandish could\", \"church yesterday\", \"climate change\", \"conclude holy\", \"could learn\", \"covid 19\", \"covid 19\", \"dangerous give\", \"das lakshan\", \"day one\", \"donald trump\", \"donald trump\", \"dukkaddam kshamavani\", \"election day\", \"election day\", \"every american\", \"every day\", \"every day\", \"exist condition\", \"exist condition\", \"fail protect\", \"faith conclude\", \"far long\", \"far long\", \"fast need\", \"fast need\", \"filipino american\", \"find peace\", \"four years\", \"four years\", \"give four\", \"government work\", \"governments interfere\", \"gun violence\", \"gun violence\", \"hard work\", \"intentionally slow\", \"interfere elections\", \"job president\", \"job president\", \"job save\", \"lakshan may\", \"lead way\", \"lead way\", \"leadership climate\", \"live need\", \"main street\", \"main street\", \"make clear\", \"make clear\", \"make history\", \"make history\", \"may find\", \"members jain\", \"men women\", \"men women\", \"michhami dukkaddam\", \"middle class\", \"middle class\", \"million americans\", \"million people\", \"must impeach\", \"must seek\", \"nation us\", \"nation us\", \"national security\", \"national security\", \"need test\", \"negligence incompetence\", \"new hampshire\", \"new hampshire\", \"one another\", \"one rejoin\", \"paris agreement\", \"paryushan das\", \"peace reconciliation\", \"people job\", \"people live\", \"planet may\", \"pre exist\", \"pre exist\", \"president intentionally\", \"president trump\", \"president trump\", \"pretty simple\", \"provide path\", \"provide path\", \"reconciliation live\", \"recover day\", \"rejoin paris\", \"repeal aca\", \"repeal aca\", \"safe harbor\", \"save people\", \"send best\", \"simple want\", \"something call\", \"soul nation\", \"soul nation\", \"stake election\", \"stake election\", \"step lead\", \"step lead\", \"supporters tuesday\", \"test need\", \"thank support\", \"thank support\", \"trump administration\", \"trump continue\", \"trump continue\", \"violate oath\", \"white house\", \"white house\", \"wish members\", \"work everyone\", \"world push\", \"years ago\", \"years ago\", \"years planet\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1706021217782063042652836452\", ldavis_el1706021217782063042652836452_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1706021217782063042652836452\", ldavis_el1706021217782063042652836452_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1706021217782063042652836452\", ldavis_el1706021217782063042652836452_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=             x    y  topics  cluster       Freq\n",
       "topic                                          \n",
       "0      0.02264  0.0       1        1  50.266906\n",
       "1     -0.02264  0.0       2        1  49.733094, topic_info=              Term      Freq     Total Category  logprob  loglift\n",
       "759    save people  1.000000  1.000000  Default  30.0000  30.0000\n",
       "530      best wish  1.000000  1.000000  Default  29.0000  29.0000\n",
       "1508     must seek  2.000000  2.000000  Default  28.0000  28.0000\n",
       "539      send best  1.000000  1.000000  Default  27.0000  27.0000\n",
       "61       hard work  1.000000  1.000000  Default  26.0000  26.0000\n",
       "...            ...       ...       ...      ...      ...      ...\n",
       "27       years ago  0.998797  2.070194   Topic2  -6.7015  -0.0303\n",
       "119    soul nation  0.877587  1.547127   Topic2  -6.8309   0.1315\n",
       "79       men women  0.871752  1.547450   Topic2  -6.8375   0.1246\n",
       "570    main street  0.839320  1.548742   Topic2  -6.8754   0.0859\n",
       "471   middle class  0.891245  2.074673   Topic2  -6.8154  -0.1464\n",
       "\n",
       "[143 rows x 6 columns], token_table=      Topic      Freq                 Term\n",
       "term                                      \n",
       "435       2  0.975873                19 20\n",
       "938       2  0.976069        @drbiden send\n",
       "1405      1  0.956944  abdication american\n",
       "1406      1  0.956894      agreement rally\n",
       "49        1  0.385812     american history\n",
       "...     ...       ...                  ...\n",
       "613       2  0.651809        work everyone\n",
       "1424      1  0.956902           world push\n",
       "27        1  0.483047            years ago\n",
       "27        2  0.483047            years ago\n",
       "1425      1  0.956815         years planet\n",
       "\n",
       "[141 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display LDA model\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model_bigrams, corpus_bigrams, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9856c37",
   "metadata": {},
   "source": [
    "Both topics are relevant to Donald Trump, but we can still find some differences. Topic 1 seems to mention America from the perspective of a nation ('american people', 'american history' are mentioned a lot), which brings connections from culture or history. While topic 2 is more close to the perspective of the state (includes 'covid 19', 'government work'), which means characterising the country by formal institutions or policy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd25a8",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a43002",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get transformers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiniteautomata/bertweet-base-sentiment-analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m sentiment_analysis \u001b[38;5;241m=\u001b[39m tweets\u001b[38;5;241m.\u001b[39mcleaned_tweets_sa\u001b[38;5;241m.\u001b[39mapply(classifier)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py:666\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    663\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferring the task automatically requires to check the hub with a model_id defined as a `str`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    664\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid model_id.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    665\u001b[0m         )\n\u001b[1;32m--> 666\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[43mget_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# Retrieve the task\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m custom_tasks:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py:393\u001b[0m, in \u001b[0;36mget_task\u001b[1;34m(model, use_auth_token)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_task\u001b[39m(model: \u001b[38;5;28mstr\u001b[39m, use_auth_token: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 393\u001b[0m         info \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstantiating a pipeline without a task set raised an error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    120\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[0;32m    121\u001b[0m         fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    122\u001b[0m     )\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\hf_api.py:1228\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m files_metadata:\n\u001b[0;32m   1227\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1228\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1234\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1235\u001b[0m d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m'\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[0;32m    527\u001b[0m }\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 440\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get transformers\n",
    "classifier = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "sentiment_analysis = tweets.cleaned_tweets_sa.apply(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be72ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save sentiment analysis result\n",
    "labels=[]\n",
    "scores=[]\n",
    "for sentiment in sentiment_analysis:\n",
    "    labels.append(sentiment[0]['label'])\n",
    "    scores.append(round(sentiment[0]['score'],4))\n",
    "    \n",
    "tweets['labels'] = labels\n",
    "tweets['scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis result \n",
    "print(tweets.groupby(['labels'])['labels'].count())\n",
    "\n",
    "neg_tweets = tweets[tweets['labels'] == 'NEG']\n",
    "neu_tweets = tweets[tweets['labels'] == 'NEU']\n",
    "pos_tweets = tweets[tweets['labels'] == 'POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 bigrams - Negative\n",
    "top_10_neg = get_top_ngram(neg_tweets['cleaned_tweets'],2)[:10] \n",
    "x1,y1 = map(list,zip(*top_10_neg)) \n",
    "sns.barplot(x = y1,y = x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd782cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 bigrams - Neutral\n",
    "top_10_neu = get_top_ngram(neu_tweets['cleaned_tweets'],2)[:10] \n",
    "x2,y2 = map(list,zip(*top_10_neu)) \n",
    "sns.barplot(x = y2,y = x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776da107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 bigrams - Positive\n",
    "top_10_pos = get_top_ngram(pos_tweets['cleaned_tweets'],2)[:10] \n",
    "x3,y3 = map(list,zip(*top_10_pos)) \n",
    "sns.barplot(x = y3,y = x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72984067",
   "metadata": {},
   "source": [
    "We can see 'donald trump' remains a high frequency in all the sentiments, but it is not the most frequent bigrams in positive sentiment. The tweets labelled as negative seem to describe Trump's term of office (as it shows 'supreme court' 'repeal aca'), while the positive tweets are more close to Biden himself (as it shows 'vice president'). And for the neutral tweets, public topics such as covid-19 are mentioned.\n",
    "\n",
    "To sum up, this project presents a descriptive and exploratory analysis for detecting Biden's campaign strategies on social media. More theoretical evidence on social media and political campaigns is needed to explain the outcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
